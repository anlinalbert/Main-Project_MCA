{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning Model (Logistic Regression) (UCI HAR Dataset)"
      ],
      "metadata": {
        "id": "HqHQVr3q1JHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GRU\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Load the training data\n",
        "train_df = pd.read_csv('X_train.txt', header=None, sep='\\s+')\n",
        "train_labels_df = pd.read_csv('y_train.txt', header=None, sep='\\s+')\n",
        "\n",
        "# Load the testing data\n",
        "test_df = pd.read_csv('X_test.txt', header=None, sep='\\s+')\n",
        "test_labels_df = pd.read_csv('y_test.txt', header=None, sep='\\s+')\n",
        "\n",
        "# Combine the data and labels\n",
        "train_df['label'] = train_labels_df[0]\n",
        "test_df['label'] = test_labels_df[0]\n",
        "\n",
        "# Merge the training and testing data\n",
        "df = pd.concat([train_df, test_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "lxvE4_3DecgP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Dataset shape:', df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFM-ZDxqezLG",
        "outputId": "5954c80b-4cf5-41e6-a675-b832cab28c05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (10299, 562)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into features and labels\n",
        "X = df.iloc[:,:-1]\n",
        "y = df['label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "xI97pSdOe2oy"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train the logistic regression model\n",
        "lr = LogisticRegression(random_state=42, max_iter=5000) # Increase max_iter to 5000\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Evaluate the model on the testing set\n",
        "y_pred = lr.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzfWYchCe5EU",
        "outputId": "e7e90570-1db0-4af7-9afe-9b3e3003ff00"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9796116504854369\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU Model Below"
      ],
      "metadata": {
        "id": "Q-d1iX9qpSL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the model architecture\n",
        "# model = Sequential()\n",
        "# model.add(GRU(32, input_shape=(X_train.shape[1], 1)))\n",
        "# model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "nPTG74B7iKt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, GRU\n",
        "# from keras.optimizers import Adam\n",
        "\n",
        "# # Load the training data\n",
        "# train_df = pd.read_csv('X_train.txt', header=None, sep='\\s+')\n",
        "# train_labels_df = pd.read_csv('y_train.txt', header=None, sep='\\s+')\n",
        "\n",
        "# # Load the testing data\n",
        "# test_df = pd.read_csv('X_test.txt', header=None, sep='\\s+')\n",
        "# test_labels_df = pd.read_csv('y_test.txt', header=None, sep='\\s+')\n",
        "\n",
        "# # Combine the data and labels\n",
        "# train_df['label'] = train_labels_df[0]\n",
        "# test_df['label'] = test_labels_df[0]\n",
        "\n",
        "# # Merge the training and testing data\n",
        "# df = pd.concat([train_df, test_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "vxXhukm9pVXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Scale the features\n",
        "# scaler = StandardScaler()\n",
        "# X = scaler.fit_transform(X)\n",
        "\n",
        "# # Split the data into training and testing sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Reshape the data for the GRU model\n",
        "# X_train = X_train.reshape(-1, 1, X.shape[1])\n",
        "# X_test = X_test.reshape(-1, 1, X.shape[1])\n",
        "\n",
        "# # Define the GRU model\n",
        "# model = Sequential()\n",
        "# model.add(GRU(64, input_shape=(1, X.shape[1])))\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # Train the model\n",
        "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "# # Evaluate the model on the testing set\n",
        "# loss, accuracy = model.evaluate(X_test, y_test)\n",
        "\n",
        "# print(\"Loss:\", loss)\n",
        "# print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "ByFgS4iaqHVX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}